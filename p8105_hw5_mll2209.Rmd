---
title: "Homework 5"
author: Michelle Lui
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in the data.

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>%
  select(city_state, resolved) %>%
  filter(city_state != "Tulsa_AL")
```

Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>%
  group_by(city_state) %>%
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved),
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>%
  broom::tidy()
```

Try to iterate...

```{r}
results_df = 
  aggregate_df %>%
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>%
  select(-prop_tests) %>%
  unnest(tidy_tests) %>%
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

```{r, error = TRUE}
city_prop_test = function(df) {
  n_unsolved ...
  n_total ...
  prop.test(.....)
}
```

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>%
  select(city_state, resolved) %>%
  filter(city_state != "Tulsa_AL") %>%
  nest(data = resolved)
```

## Problem 2

import one dataset

```{r}
data_1 = read_csv("lda_data/con_01.csv")
```

Create tibble

```{r}
setwd("lda_data/")
path_df = 
  tibble(
    path = list.files()
  )
path_df = 
  path_df %>%
  mutate(
    data = map(path_df$path, read_csv)
  )
```

Tidy results

```{r}
trial_unnest = 
  unnest(path_df, cols = data) %>%
  separate(path, sep = "_", into = c("arm", "subject_id")) %>%
  mutate(subject_id = str_replace(subject_id, "\\.csv", "")) %>%
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "obs") %>%
  mutate(week = str_replace(week, "week_", "")) %>%
  mutate(arm = str_replace(arm, "con", "control")) %>%
  mutate(arm = str_replace(arm, "exp", "experimental"))

```

Spaghetti plot!

```{r}
  trial_unnest %>%
  ggplot(aes(x = week, y = obs, group = interaction(arm,subject_id), color = arm)) + 
  geom_point() + geom_line() +
  labs(title = "Observations on each subject over time", 
       x = "Week", 
       y = "Observations")
```
From the spaghetti plot, it seems that over time, on average the control group has lower observations when compared to the experimental group, since in the graph the lines corresponding to the experimental group are higher than the lines corresponding to the control group. 

## Problem 3

Setting the function
```{r}
sim_t_test = function(n = 30, mu = 0, sigma = 5) {
  sim_data = tibble(
    x = rnorm(n = n, mean = mu, sd = sigma)
  )
  
  sim_data %>%
    summarize(
      mu_hat = mean(x),
      sigma_hat = sd(x),
      t.test(sim_data, mu = 0, alternative = 'two.sided', paried = FALSE, conf.level = 0.95) %>%
      broom::tidy())
}
```

Set mu = 0, generate 5000 datsets from the model made above, save mu_hat and p-value for each dataset
```{r}
output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = sim_t_test(30)
}
sim_results = 
  bind_rows(output) %>%
  select(mu_hat, p.value)
```

Repeat the above for mu = 1 through 6
```{r}
sim_results1 = 
  tibble(true_mu = c(1, 2, 3, 4, 5, 6)) %>%
  mutate(
    output_lists = map(.x = true_mu, ~rerun(5000, sim_t_test(mu = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>%
  select(-output_lists) %>%
  unnest(estimate_dfs) %>%
  select(true_mu, mu_hat, p.value)
  
```

Make plot showing proportion of times null was rejected
```{r}
  sim_results1 %>%
  mutate(
    test  = case_when(
      p.value <= 0.05 ~ "reject",
      p.value > 0.05 ~ "fail to reject")) %>%
  select(-mu_hat, -p.value) %>%
  group_by(true_mu, test) %>%
  summarize(n = n()) %>%
  mutate(reject_freq = n / sum(n)) %>%
  filter(test == "reject") %>%
  ggplot(aes(x = true_mu, y = reject_freq)) + 
  geom_point() +
  labs(title = "Proportion of times null was rejected for each true value of mu", 
       x = "True value of mu", 
       y = "Proportion of times null was rejected")
```
As the effect size increases, the power of the test also increases, until it becomes large enough and plateaus at 1.

Make plot showing average estimate of mu hat and true mu. 
```{r}
  sim_results1 %>%
  mutate(
    test  = case_when(
      p.value <= 0.05 ~ "reject",
      p.value > 0.05 ~ "fail to reject")) %>%
  group_by(true_mu) %>%
  summarize(mean = mean(mu_hat)) %>%
  ggplot(aes(x = true_mu, y = mean)) +
  geom_point() + 
  labs(title = "Average estimate of mu hat for each true value of mu", 
       x = "True value of mu", 
       y = "Average estimate of mu hat") +
  scale_y_continuous(
    breaks = c(0, 2, 4, 6)
  )
```

Make second plot with average estimate of mu hat for which the null was rejected and the true value of mu
```{r}
  sim_results1 %>%
  mutate(
    test  = case_when(
      p.value <= 0.05 ~ "reject",
      p.value > 0.05 ~ "fail to reject")) %>%
  filter(test == "reject") %>%
  group_by(true_mu) %>%
  summarize(mean = mean(mu_hat)) %>%
  ggplot(aes(x = true_mu, y = mean)) +
  geom_point() +
  labs(title = "Average estimate of mu hat for each true value of mu, among rejected", 
       x = "True value of mu", 
       y = "Average estimate of mu hat") +
  scale_x_continuous(expand = c(0, 0), limits = c(0, NA)) + 
  scale_y_continuous(expand = c(0, 0), limits = c(0, NA))
```

The sample average of mu hat across tests for which the null is rejected is not approximately equal to the true value of mu, because values that are appreciably different from the true mu get rejected because they will have a larger effect size and smaller p value. Since the averages among samples where the null was rejected is composed of these larger values, the sample average of mu across tests in this situation will be larger than the true value of mu as we see in the graph.
